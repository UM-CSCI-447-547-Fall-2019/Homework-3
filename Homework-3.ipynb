{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3: Softmax Regression\n",
    "## Due October 3rd\n",
    "\n",
    "## 1 Loading Digits\n",
    "One of the most common uses of contemporary machine learning applications is in the processing of large image datasets.  One of the earliest commercial applications of ML was in mapping a handwritten digit (say, from a scanned copy of a check) to its corresponding digital representation.  This fits very well in our framework for machine learning if we recognize that the pixel values in an image can be viewed as a vector of features $\\mathbf{x}$, and that the prediction that we're aiming for is the numerical digit:\n",
    "$$\n",
    "\\mathcal{F}(\\mathbf{x},\\mathbf{w}) = y\n",
    "$$\n",
    "$$\n",
    "y \\in \\{0,1,\\ldots,9\\}.\n",
    "$$\n",
    "In this exercise, we will use softmax regression as a model to map 8x8 grayscale images to digit labels.  \n",
    "\n",
    "Our first course of action will be to load a dataset. Fortunately, scikit-learn comes prepackaged with this dataset, simply called \"the digits dataset\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets  # Import the sklearn datasets module\n",
    "\n",
    "data = datasets.load_digits()\n",
    "x = data.data\n",
    "y = data.target\n",
    "\n",
    "x_train,x_test,y_train,y_test =  model_selection.train_test_split(x,y)\n",
    "\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the shape of $x$.  It has 1797 digit instances and 64 features.  The 64 entries represent a flattened version of an 8x8 image.  In fact, if we want to recover the associated image, we can just reshape the entry back into an 8x8 array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x[547,:].reshape((8,8)))\n",
    "print(\"This digit is a\",y[547])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, for this model, we'll be using the flattened version.\n",
    "\n",
    "## 2 Training digits (50 pts)\n",
    "**Your task is to train a softmax regression model that takes an image from the digits dataset, and outputs a (hopefully accurate) prediction of what digit it is.** The application should be quite similar to what we did for the Iris dataset, albeit with a different $m$, $n$ (4 vs 64), and $N$ (3 vs 10).  The steps are as follows:\n",
    "- Encode $y$ using a one-hot scheme.\n",
    "- Initialize a weight matrix (n by N).\n",
    "- Implement the softmax function.\n",
    "- Implement the categorical cross-entropy function.\n",
    "- Implement a function that returns the gradient of the objective function with respect to the weight matrix.\n",
    "- Use gradient descent to find good values for $W$.  You may have to tune your learning rate $\\eta$, and you'll want to devise a stopping criterion.\n",
    "\n",
    "**After training your model, report the accuracy on both the training and test sets.**  Just for comparison, softmax regression yields around 97\\% accuracy for me (albeit your numbers will vary due to the randomness in the dataset splitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Training MNIST (25 pts)\n",
    "The digits problem is interesting, but it's hardly 'big'.  It's also very low resolution, and has been heavily curated.  A more realistic dataset is given by the so-called [MNIST Dataset](https://en.wikipedia.org/wiki/MNIST_database), which is a set of over 70000 28x28 digits.  We can load it easily using scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets  # Import the sklearn datasets module\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Load the dataset\n",
    "data = datasets.fetch_mldata('MNIST original')\n",
    "x = data.data/255.  # Note that MNIST hasn't yet been scaled to 0-1 from the original 8 it.  Dividing by 2^8 does this for us\n",
    "y = data.target\n",
    "\n",
    "plt.imshow(x[25000].reshape(28,28))\n",
    "print(\"This digit is a\",y[25000])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adapt your code from above, and apply it to the MNIST dataset.** If your code is written sensibly, this should take almost no modification.  What it *will* require is substantially more computational time: be sure that your code is working properly on the digits dataset before graduating to MNIST.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Visualizing MNIST weights (25 pts)\n",
    "Assuming that you've implemented softmax regression correctly, we'll have 785 weights associated with each class (if you use similar code to what I used for irises, this will be the 785 by 10 matrix $W$).  Recognizing that one of these 785 weights is the bias, that means that the remaining 784 weights (per class) are associated with exactly 1 pixel in the input image, and we can thus organize our weights into an *image*.  By doing this, we can learn a bit about the coherent structure that the softmax regressor is learning!\n",
    "\n",
    "**Reshape your learned weights (excluding the bias parameters) to be an image of the same shape as the MNIST dataset (28 by 28).  Produce a plot of each of these ten images.**  You should see a fairly clear picture emerge. if you're seeing something that looks like white noise, then check to ensure you are reshaping the array in the correct order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use these pictures of the weights to explain to me how softmax regression works as if I was your grandparent.  (This section will be graded both on technical correctness and accessibility!)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
